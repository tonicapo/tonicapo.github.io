<!doctype html><html lang="fr"><head><meta charset="utf-8"><meta name="description" content="Antonio Capobianco, enseignant chercheur à l'université de Strasbourg. Réalité virtuelle, intéraction 3D, Jeux sérieux."><meta name="keywords" content="VR, Virtual réality, 3D interaction, Serious games, assistant professor, Strasbourg university, RV, réalité virtuelle, interaction 3D"><meta name="viewport" content="initial-scale=1"><title>Antonio Capobianco - Enseignant chercheur</title><link rel="stylesheet" href="style.css"><link rel="stylesheet" href="dynamic.min.css"></head><body><header><div class="wrapper clearfix"><div class="left"><h1><a href="index.html">Antonio<br>Capobianco</a></h1><h2>Enseignant Chercheur, Université de Strasbourg</h2></div><ul class="right"><a href="http://iuthaguenau.unistra.fr/"><li class="sprite-container sprite-iut"></li></a> <a href="http://www.unistra.fr/index.php?id=accueil"><li class="sprite-container sprite-uds"></li></a> <a href="http://icube.unistra.fr/"><li class="sprite-container sprite-icube"></li></a> <a href="http://icube-igg.unistra.fr/fr/index.php/Accueil"><li class="sprite-container sprite-igg"></li></a> <a href="http://www.cnrs.fr/"><li class="sprite-container sprite-cnrs"></li></a></ul></div></header><div class="navcontainer"><div class="ref"><nav class="animated"><div id="mobilemenu" class="wrapper clearfix tabled maxheight"><div class="celled maxheight"><h1>A. Capobianco</h1><h2>Enseignant chercheur, université de strasbourg</h2></div><div id="menubutton" class="celled"><span class="icon-menu"></span></div></div><ul class="wrapper animated"><li><a href="index.html"><span class="icon-Home"></span><span class="home-text">Accueil</span></a></li><li class="current"><a href="recherche.html">Recherche</a></li><li><a href="publications.html">Publications</a></li><li><a href="projets.html">Projets</a></li><li><a href="encadrement.html">Encadrement</a></li></ul></nav></div></div><article class="wrapper maincontent"><section class="clearfix articlesection"><h1 class="mainh1">Manipulation et édition de modèles 3D en réalité virtuelle</h1><div class="textcontent left"><p>L’équipe <a class="dotted" href="http://icube-igg.unistra.fr/fr/index.php/Accueil">IGG</a> a pour thématique principale la géométrie et ses applications en modélisation géométrique. Elle travaille à la définition de modèles combinatoires adaptatifs, multi-résolutions, plongés grâce des surfaces de subdivision. Les travaux réalisés dans le thème de recherche « Visualisation et interaction en environnement virtuel » s’appuient sur ces résultats, et visent à proposer des techniques d’interaction permettant d’interagir avec ces modèles à tous les niveaux. Nous souhaitons manipuler, déformer, éditer, aussi bien la topologie des modèles 3D sur lesquels nous travaillons, que leur plongement et cela directement dans des environnements virtuels immersifs.</p><p>Dans ce cadre applicatif, l’utilisation de techniques d’interaction 3-D semble être en adéquation avec la nature tridimensionnelle des tâches impliquées (positionnement dans un espace 3-D, orientation, déformation d’un objet, sculpture, etc.). Cependant, la sélection et la manipulation d'objets virtuels complexes soulèvent de nombreuses difficultés. De telles manipulations requièrent un niveau de précision qu’il est difficile d’atteindre avec des techniques de manipulation 3D classiques.</p><p>En effet, de nombreuses techniques proposées jusqu’à présent utilisent des gestes libres de toutes contraintes. L'absence de contraintes d'interaction est perçue comme un facteur pouvant améliorer significativement les performances des utilisateurs, dans la mesure où ces techniques respectent le principe de manipulation directe. Par exemple, pour effectuer une déformation, l’utilisateur peut, en un seul geste, désigner la partie de l’objet à déformer et définir la trajectoire de déformation.</p><p>De fait, ce paradigme d’interaction permet généralement de réduire les temps de réalisation. Toutefois, l’ajout de la profondeur dans l’espace de manipulation semble introduire de nouvelles difficultés. Plus le nombre de degrés de liberté à manipuler simultanément est important plus la complexité de la tâche croît. Il semblerait qu’il en découle une augmentation de la charge cognitive qui entraîne une baisse des performances des utilisateurs, notamment en matière de précision.</p><p>L'approche que nous proposons consiste à essayer de diminuer la dimensionnalité de l’espace de la technique d’interaction. Pour cela, nous avons recours soit à des contraintes physiques soit à des contraintes virtuelles. En réduisant le nombre de degrés de libertés qui sont contrôlés simultanément, notre objectif est de réduire la charge cognitive induite par la tâche, en vue d'améliorer les performances de l'utilisateur. Nous avons proposé plusieurs solutions et techniques d'interaction qui s'inscrivent dans cette démarche.</p></div><figure class="figcontent right"><img class="figimg" src="./images/dinosaure.png" alt="Modèle de dinosaure mutli-résolution"> <img class="figimg" src="./images/horse.png" alt="Modèle de cheval mutli-résolution"><figcaption>Deux exemples de modèles multi-résolutions que nous souhaitons pouvoir éditer en réalité virtuelle.</figcaption></figure></section><section><h1 class="mainh1">Techniques d'interaction proposées</h1><div class="clearfix"><div class="textcontent left"><h2>DIOD : Decomposition and Integration Of Degrees of freedom</h2><p>Nous proposons une technique hybride pour la tâche de positionnement 3-D, <em>Decomposition and Integration Of Degrees of freedom</em> (notée DIOD). Elle repose sur l'idée de mettre à l’échelle le déplacement de l’objet en fonction de la vitesse de déplacement du périphérique d’interaction. On peut en effet considérer deux phases de manipulation lors d'un même geste de contrôle :</p><ul class="shifted"><li>Lorsque l’utilisateur se déplace rapidement, il désire s’approcher grossièrement de la cible et n’a dans ce cas aucun besoin de précision ;</li><li>Lorsque l’utilisateur se déplace lentement, l’utilisateur est à proximité de la cible et, dans ce cas, a besoin d’un contrôle précis.</li></ul><p>Cette technique a pour objectif de fournir un contrôle adapté, en matière de coordination des degrés de liberté, au cours des deux phases de la tâche. Elle permet de manipuler simultanément l’ensemble des dimensions de l’espace lorsque l’utilisateur s’approche grossièrement de la cible. Lorsque l’utilisateur corrige la position de l’objet manipulé, la technique passe à un mode de contrôle permettant de manipuler moins de DDL à la fois afin de permettre à l’utilisateur de se concentrer sur la manipulation de DDL particuliers. La distinction entre ces deux phases se fait automatiquement à partir de l'analyse de la vitesse du mouvement.</p></div><figure class="figcontent right"><img class="figimg" src="./images/diod.png" alt="Principe de fonctionnement de DIOD"><figcaption>Principe de fonctionnement de DIOD : la transition entre la phase de manipulation à l’échelle 1:1 et la phase de manipulation contrainte se fait en douceur grâce à un principe de filtrage par dimension. Le geste de contrôle est progressivement contraint à une manipulation à un degré de liberté.</figcaption></figure></div><div class="clearfix margintop2em"><div class="textcontent left"><h2>CrOS : Cursor On Surface</h2><p>En modélisation géométrique, de nombreux opérateurs nécessitent de manipuler sur la surface même des objets 3-D. C’est le cas par exemple pour l’opérateur de sculpture. En l’absence de toute assistance, il est pratiquement impossible de manipuler sur la surface même de l’objet. Les concepteurs introduisent alors des contraintes virtuelles dans le but d’offrir aux utilisateurs un meilleur contrôle et une meilleure précision.</p><p>Nous proposons donc une technique permettant d’interagir sur la surface d’un objet 3-D en utilisant une interface tactile. Le support physique introduit par la présence de l’écran se trouvant à portée de main permet :</p><ul class="shifted"><li>De réduire la dimension de l’espace de manipulation et de la tâche. Réduire la dimensionnalité de la tâche peut permettre de réduire la charge cognitive induite durant la réalisation de la tâche et d’améliorer la précision;</li><li>D’améliorer la précision lors de la manipulation par l’introduction d’un support physique ;</li><li>D’accroître le confort de l’interaction en réduisant la fatigue induite.</li></ul><p>Nous supposons qu'il est donc possible de définir un déplacement sur la surface de l’objet 3-D à partir d’un vecteur dans un espace 2-D (nous nous limitons donc au cas où l’objet est une 2-variété). On peut donc définir les trajectoires de déplacement du pointeur à la surface de l'objet 3-D en utilisant une surface tactile. L’utilisateur effectue alors les opérations de modélisation, non pas en utilisant une technique de manipulation directe, mais en utilisant un curseur se déplaçant sur la surface même de l’objet.</p></div><figure class="figcontent right"><img class="figimg" src="./images/cros.png" alt="Principe de fonctionnement de CrOS"><figcaption>Principe de fonctionnement de CrOS : le chemin géodésique correspondant à un déplacement 2-D peut être considéré comme l’intersection locale entre un plan contenant le déplacement 2-D passant par la position du curseur. Cette figure illustre la relation entre l’intersection du plan et de la surface et le chemin géodésique associé au déplacement 2-D.</figcaption></figure></div></section><section class="clearfix"><div class="textcontent left"><h1 class="mainh1">Travaux de recherche en cours</h1><p>Les environnements de réalité virtuelle ont considérablement évolué au cours des dernières années et tendent à se démocratiser. Des dispositifs comme l'<a class="dotted" href="http://www.oculusvr.com/">Oculus Rift</a> ® et la <a class="dotted" href="https://www.leapmotion.com/">Leap Motion</a> ® ont fait sortir la réalité virtuelle du cadre des centres de recherche, et ouvrent la voie à de nouveaux paradigmes d’interaction. Dans le même temps, les périphériques tactiles deviennent de véritables dispositifs universels d’interaction, et offrent la possibilité de lever de nombreux verrous posés par les techniques d’interaction classiques (sélection précise d’items dans un environnement immersif, problématique de la saisie de texte, etc.).</p><p>Les différentes techniques d’interaction que nous avons proposées (DIOD, CrOS, Starfish) s’adaptent parfaitement à ces nouveaux contextes d’interaction. Mais différents verrous scientifiques demeurent. En effet, si les périphériques tactiles permettent d’envisager l’utilisation de ces techniques assez facilement, les conséquences pour l’utilisateur et les contraintes d’usages qui s’y rattachent restent à étudier.</p><p>On peut par exemple envisager la création d’environnements de « réalité virtuelle augmentée » en tirant parti de l’écran des terminaux tactiles pour enrichir les informations données à l’utilisateur, sans surcharger visuellement l’environnement. Néanmoins, on peut imaginer que le passage successif d’un écran 2D à un environnement 3D soit préjudiciable à l’immersion et à la présence, qui demeurent des atouts majeurs de la réalité virtuelle à ce jour. Le véritable potentiel de l’utilisation des périphériques tactiles pour l’interaction 3D reste donc à évaluer.</p><p>Parallèlement à cette approche centrée sur l’utilisation de périphériques tactiles, je souhaite développer de nouvelles techniques d’interaction basées sur la reconnaissance de gestes. Cette approche s’inscrit parfaitement dans le contexte des nouveaux périphériques d’interaction qui sont apparus ces dernières années. Cet axe de recherche sera développé dans le cadre du projet 3D Surg (voir la page <a class="dotted" href="projets.html">Projets</a>), qui vise à proposer des outils d’interaction aux chirurgiens en salle d’opération. Ceux-ci devront permettre au praticien de consulter les données médicales 3D des patients afin de l’aider dans la planification et la réalisation de l’opération. Ces données 3D seront présentées sur des tablettes tactiles et les techniques d’interaction proposées devront s’adapter aux contraintes du bloc opératoire. L’approche sera complémentaire des différents travaux proposés autour de l’interaction via périphériques tactiles. En effet, les contraintes du bloc opératoire nécessitent de mettre au point des techniques d’interaction « sans contact ». Les modalités d’interaction proposées devront donc reposer uniquement sur la définition d’un langage d’interaction à base de gestes.</p></div></section></article><footer><div class="wrapper clearfix"><article class="contact"><div><h1>Antonio Capobianco</h1><h2>Enseignant Chercheur, Université de Strasbourg</h2></div><div><h3>Me contacter</h3><ul class="social"><li><a href="mailto:a.capobianco@unistra.fr"><span class="icon-email"><span class="none">M'envoyer un mail</span></span></a></li><li><a href="http://twitter.com/LamiTransalpin"><span class="icon-twitter-sign"><span class="none">Me suivre sur Twitter</span></span></a></li><li><a href="https://plus.google.com/+AntonioCapobianco/posts?rel=author"><span class="icon-google-plus-sign"><span class="none">Me suivre sur Google+</span></span></a></li></ul></div></article><article class="twitter"><h1>Twitter</h1><a class="twitter-timeline" href="https://twitter.com/LamiTransalpin" data-widget-id="304673785091592192" data-chrome="noheader nofooter" data-tweet-limit="5">Tweets de @LamiTransalpin</a><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script></article><article class="menu"><h1>Menu</h1><ul><li><a href="index.html">Accueil</a></li><li><a href="recherche.html">Recherche</a></li><li><a href="publications.html">Publications</a></li><li><a href="projets.html">Projets</a></li><li><a href="encadrement.html">Encadrement</a></li></ul></article></div><div class="signature"><p class="wrapper">© Antonio Capobianco.</p></div></footer><script src="http://ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js"></script><script>window.jQuery || document.write('<script src="js/jquery-1.8.3.min.js"><\/script>')</script><script type="text/javascript" src="./js/jquery-1.10.2.min.js"></script><script src="./js/scripts.min.js"></script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-44143817-1', 'tonicapo.github.io');
              ga('send', 'pageview');</script></body></html>